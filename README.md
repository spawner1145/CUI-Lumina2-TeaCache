# cui-teacache-lu2
## referenced from https://github.com/spawner1145/TeaCache/blob/main/TeaCache4Lumina2/teacache_lumina2.py
## firstly transplanted by [@fexli](https://github.com/fexli)
## retransplanted by @spawner
## Installation

### Manual installation

```bash
// switch to your project's root directory
cd custom_nodes
git clone https://github.com/spawner1145/CUI-Lumina2-TeaCache.git
```

### Installation via comfyui-manager

1. Open ComfyUI WebUI
2. Navigate to `Manager` -> `Install Custom Node`
3. Enter `CUI-Lumina2-TeaCache` in the `Search` field, and click `Search`
4. Click `Install`

# usage
![image](https://github.com/user-attachments/assets/fae7bebe-3af1-48f4-9a22-432bb6b9b4fa)
1. Connect the `TeaCache` node between the `UNet Loader` and `KSampler` in your workflow.
2. Set the `rel_l1_thresh` parameter to a value greater than 0.
3. to work on low steps, you can set the value below to `[393.76566581, -603.50993606, 209.10239044, -23.00726601, 0.86377344]` and a small `rel_l1_thresh` like 0.3 for higher speed or set the value below to `[225.7042019806413, -608.8453716535591, 304.1869942338369, 124.21267720116742, -1.4089066892956552]` and a very large `rel_l1_thresh` like 5 for higher speed and better quality, and for higher steps, you can set the value below to `[225.7042019806413, -608.8453716535591, 304.1869942338369, 124.21267720116742, -1.4089066892956552]` and a `rel_l1_thresh`<1.1 to get better quality and higher speed.

**Note:** 
- Higher `rel_l1_thresh` values will improve generation efficiency (manifested as shorter generation times), at the cost of reduced image quality.
- The optimal value should be determined through empirical testing based on your specific quality/efficiency requirements.

# reference
[TeaCache](https://github.com/LiewFeng/TeaCache) can speedup [Lumina-Image-2.0](https://github.com/Alpha-VLLM/Lumina-Image-2.0) without much visual quality degradation, in a training-free manner. The following image shows the results generated by TeaCache-Lumina-Image-2.0 with various rel_l1_thresh values: 0 (original), 0.2 (1.25x speedup), 0.3 (1.5625x speedup), 0.4 (2.0833x speedup), 0.5 (2.5x speedup).

<p align="center">
    <img src="https://github.com/user-attachments/assets/d2c87b99-e4ac-4407-809a-caf9750f41ef" width="150" style="margin: 5px;">
    <img src="https://github.com/user-attachments/assets/411ff763-9c31-438d-8a9b-3ec5c88f6c27" width="150" style="margin: 5px;">
    <img src="https://github.com/user-attachments/assets/e57dfb60-a07f-4e17-837e-e46a69d8b9c0" width="150" style="margin: 5px;">
    <img src="https://github.com/user-attachments/assets/6e3184fe-e31a-452c-a447-48d4b74fcc10" width="150" style="margin: 5px;">
    <img src="https://github.com/user-attachments/assets/d6a52c4c-bd22-45c0-9f40-00a2daa85fc8" width="150" style="margin: 5px;">
</p>

## ðŸ“ˆ Inference Latency Comparisons on a single 4090 (step 50)


|      Lumina-Image-2.0      |        TeaCache (0.2)       |    TeaCache (0.3)    |     TeaCache (0.4)    |     TeaCache (0.5)    |
|:-------------------------:|:---------------------------:|:--------------------:|:---------------------:|:---------------------:|
|         ~25 s             |        ~20 s                |     ~16 s            |       ~12 s             |       ~10 s             |

# special thanks
## [fexli](https://github.com/fexli)
The original TeaCache transplant of Lumina2 in cui

## [welltop-cn](https://github.com/welltop-cn/ComfyUI-TeaCache)
model patch code design
